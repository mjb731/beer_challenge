{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import random\n",
    "import spacy\n",
    "from spacy.pipeline.textcat_multilabel import Config, multi_label_cnn_config\n",
    "from spacy.training.example import Example\n",
    "from spacy.util import minibatch, compounding\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "beers = pd.read_csv('./BeerDataScienceProject.csv', encoding ='latin1')\n",
    "# get an idea of what the data looks like\n",
    "print(beers.describe())\n",
    "print(beers.columns)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "            beer_ABV    beer_beerId  beer_brewerId  review_appearance  \\\n",
      "count  508590.000000  528870.000000  528870.000000      528870.000000   \n",
      "mean        7.017442   22098.466016    2598.423429           3.864522   \n",
      "std         2.204460   22158.284352    5281.805350           0.604010   \n",
      "min         0.010000       3.000000       1.000000           0.000000   \n",
      "25%         5.300000    1745.000000     132.000000           3.500000   \n",
      "50%         6.500000   14368.000000     394.000000           4.000000   \n",
      "75%         8.500000   40528.000000    1475.000000           4.000000   \n",
      "max        57.700000   77310.000000   27980.000000           5.000000   \n",
      "\n",
      "       review_palette  review_overall   review_taste   review_aroma  \\\n",
      "count   528870.000000   528870.000000  528870.000000  528870.000000   \n",
      "mean         3.758926        3.833197       3.765993       3.817350   \n",
      "std          0.685335        0.709962       0.669018       0.718903   \n",
      "min          1.000000        0.000000       1.000000       1.000000   \n",
      "25%          3.500000        3.500000       3.500000       3.500000   \n",
      "50%          4.000000        4.000000       4.000000       4.000000   \n",
      "75%          4.000000        4.500000       4.000000       4.500000   \n",
      "max          5.000000        5.000000       5.000000       5.000000   \n",
      "\n",
      "        review_time  \n",
      "count  5.288700e+05  \n",
      "mean   1.224885e+09  \n",
      "std    7.605600e+07  \n",
      "min    8.843904e+08  \n",
      "25%    1.174613e+09  \n",
      "50%    1.240366e+09  \n",
      "75%    1.288560e+09  \n",
      "max    1.326277e+09  \n",
      "Index(['beer_ABV', 'beer_beerId', 'beer_brewerId', 'beer_name', 'beer_style',\n",
      "       'review_appearance', 'review_palette', 'review_overall', 'review_taste',\n",
      "       'review_profileName', 'review_aroma', 'review_text', 'review_time'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "    # 1. Rank top 3 Breweries which produce the strongest beers?\n",
    "    # 2. Which year did beers enjoy the highest ratings? \n",
    "    # 3. Based on the userâ€™s ratings which factors are important among taste, aroma, appearance, and palette?\n",
    "    # 4. If you were to recommend 3 beers to your friends based on this data which ones will you recommend?\n",
    "    # 5. Which Beer style seems to be the favorite based on reviews written by users? \n",
    "    # 6. How does written review compare to overall review score for the beer styles?\n",
    "    # 7. How do find similar beer drinkers by using written reviews only?       "
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "    # 1. Rank top 3 Breweries which produce the strongest beers?\n",
    "\n",
    "# remove duplicate beer listings (because of multiple reviews)\n",
    "beers_groups_by_brewer = beers.drop_duplicates(['beer_brewerId', 'beer_name'],keep= 'last').groupby(['beer_brewerId'], axis=0).mean()\n",
    "print(beers_groups_by_brewer.nlargest(3, 'beer_ABV')['beer_ABV'])"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "beer_brewerId\n",
      "6513     24.690000\n",
      "736      13.500000\n",
      "24215    12.466667\n",
      "Name: beer_ABV, dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "    # 2. Which year did beers enjoy the highest ratings? \n",
    "beers['review_year'] = pd.to_datetime(beers['review_time'], unit='s').dt.year\n",
    "beers_groups_by_year = beers.groupby(['review_year'], axis=0).mean()\n",
    "print(beers_groups_by_year.nlargest(3, 'review_appearance')['review_appearance'])\n",
    "print(beers_groups_by_year.nlargest(3, 'review_palette')['review_palette'])\n",
    "print(beers_groups_by_year.nlargest(3, 'review_overall')['review_overall'])\n",
    "print(beers_groups_by_year.nlargest(3, 'review_taste')['review_taste'])\n",
    "print(beers_groups_by_year.nlargest(3, 'review_aroma')['review_aroma'])\n",
    "\n",
    "beers_groups_by_year = beers_groups_by_year[['review_appearance', 'review_palette', 'review_taste', 'review_aroma', 'review_overall']]\n",
    "\n",
    "# highest ratings = sum of all ratings, out of 25 total\n",
    "beers_groups_by_year[\"sum_column\"] = beers_groups_by_year.sum(1)\n",
    "print(beers_groups_by_year['sum_column'])\n",
    "beers_groups_by_year = beers_groups_by_year.sort_values(\"sum_column\", ascending=False)\n",
    "beers_groups_by_year = beers_groups_by_year.drop(\"sum_column\", axis=1)\n",
    "\n",
    "# graph that is sorted, with highest rankings first\n",
    "ax = beers_groups_by_year.plot.bar(stacked=True)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "review_year\n",
      "2000    3.909091\n",
      "2010    3.897788\n",
      "2012    3.896226\n",
      "Name: review_appearance, dtype: float64\n",
      "review_year\n",
      "2000    3.939394\n",
      "2010    3.798502\n",
      "2012    3.797170\n",
      "Name: review_palette, dtype: float64\n",
      "review_year\n",
      "2000    4.181818\n",
      "1999    4.000000\n",
      "2001    3.927741\n",
      "Name: review_overall, dtype: float64\n",
      "review_year\n",
      "2000    3.984848\n",
      "1999    3.820000\n",
      "2010    3.808075\n",
      "Name: review_taste, dtype: float64\n",
      "review_year\n",
      "2000    4.196970\n",
      "1999    3.960000\n",
      "1998    3.956522\n",
      "Name: review_aroma, dtype: float64\n",
      "review_year\n",
      "1998    18.478261\n",
      "1999    19.160000\n",
      "2000    20.212121\n",
      "2001    19.197674\n",
      "2002    18.710724\n",
      "2003    18.535960\n",
      "2004    18.764680\n",
      "2005    18.974145\n",
      "2006    18.809484\n",
      "2007    18.844133\n",
      "2008    19.027533\n",
      "2009    19.198282\n",
      "2010    19.219763\n",
      "2011    19.123182\n",
      "2012    19.155975\n",
      "Name: sum_column, dtype: float64\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "def get_adjectives_and_nouns(review):\n",
    "    adjs = set()\n",
    "    nouns = set()\n",
    "    for rev in review:\n",
    "        if rev.pos_ == 'ADJ':\n",
    "            adjs.add(rev.text.lower())\n",
    "        if rev.pos_ == 'NOUN':\n",
    "            nouns.add(rev.text.lower())\n",
    "    return nouns, adjs\n",
    "\n",
    "def get_reviews(reviws):\n",
    "    review_nouns = Counter()\n",
    "    review_adjs = Counter()\n",
    "    for doc in reviews:\n",
    "    # for review in reviews:\n",
    "        if isinstance(doc, float):\n",
    "            continue\n",
    "        nlp_review = nlp(doc)\n",
    "        nouns, adjs = get_adjectives_and_nouns(nlp_review)\n",
    "        review_nouns.update(nouns)\n",
    "        review_adjs.update(adjs)\n",
    "        # print(adjs, nouns)\n",
    "        # print(len(review_nouns), len(review_adjs))\n",
    "\n",
    "    # print(review_nouns.most_common())\n",
    "    # print(review_adjs.most_common())\n",
    "\n",
    "    return review_nouns, review_adjs\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "    # 3. Based on the userâ€™s ratings which factors are important among taste, aroma, appearance, and palette?\n",
    "\n",
    "    # check the adjectives and the nouns of the highest ratings in each category\n",
    "    # then count with adjectives and nouns were most frequetly used\n",
    "    # as those would be the most important factors\n",
    "\n",
    "    reviews = beers[beers['review_taste'] > 4.5]['review_text']\n",
    "\n",
    "    runs = 1000\n",
    "    reviews = beers[beers['review_taste'] >= 4.5]['review_text'].head(runs)\n",
    "    review_taste_nouns, review_taste_adjs = get_reviews(reviews)\n",
    "\n",
    "    reviews = beers[beers['review_aroma'] >= 4.5]['review_text'].head(runs)\n",
    "    review_aroma_nouns, review_aroma_adjs = get_reviews(reviews)\n",
    "\n",
    "    reviews = beers[beers['review_appearance'] >= 4.5]['review_text'].head(runs)\n",
    "    review_appearance_nouns, review_appearance_adjs = get_reviews(reviews)\n",
    "\n",
    "    reviews = beers[beers['review_palette'] >= 4.5]['review_text'].head(runs)\n",
    "    review_palette_nouns, review_palette_adjs = get_reviews(reviews)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "# answers to question 3\n",
    "\n",
    "print('review_taste_nouns', review_taste_nouns.most_common(20))\n",
    "print('review_taste_adjs', review_taste_adjs.most_common(20))\n",
    "print('review_aroma_nouns', review_aroma_nouns.most_common(20))\n",
    "print('review_aroma_adjs', review_aroma_adjs.most_common(20))\n",
    "print('review_appearance_nouns', review_appearance_nouns.most_common(20))\n",
    "print('review_appearance_adjs', review_appearance_adjs.most_common(20))\n",
    "print('review_palette_nouns', review_palette_nouns.most_common(20))\n",
    "print('review_palette_adjs', review_palette_adjs.most_common(20))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "review_taste_nouns [('head', 861), ('beer', 578), ('taste', 478), ('chocolate', 447), ('carbonation', 422), ('malt', 387), ('glass', 338), ('coffee', 327), ('flavor', 316), ('bit', 316), ('alcohol', 310), ('lacing', 309), ('finish', 309), ('hops', 284), ('aroma', 280), ('color', 273), ('body', 259), ('flavors', 256), ('nose', 256), ('vanilla', 245)]\n",
      "review_taste_adjs [('nice', 472), ('dark', 463), ('sweet', 383), ('good', 374), ('black', 363), ('smooth', 323), ('thick', 300), ('roasted', 300), ('great', 283), ('little', 277), ('creamy', 276), ('brown', 266), ('full', 258), ('bitter', 226), ('more', 222), ('big', 206), ('light', 189), ('rich', 175), ('bodied', 168), ('slight', 166)]\n",
      "review_aroma_nouns [('head', 838), ('beer', 603), ('taste', 469), ('carbonation', 394), ('malt', 385), ('color', 341), ('glass', 325), ('flavor', 323), ('hops', 322), ('finish', 314), ('bit', 305), ('lacing', 304), ('chocolate', 304), ('aroma', 274), ('alcohol', 250), ('flavors', 247), ('body', 245), ('hop', 244), ('notes', 233), ('nose', 231)]\n",
      "review_aroma_adjs [('nice', 463), ('good', 406), ('sweet', 358), ('dark', 346), ('great', 288), ('little', 261), ('smooth', 259), ('thick', 247), ('black', 232), ('full', 227), ('more', 223), ('bitter', 222), ('big', 215), ('white', 209), ('roasted', 208), ('light', 206), ('brown', 196), ('bodied', 178), ('creamy', 173), ('medium', 169)]\n",
      "review_appearance_nouns [('head', 850), ('beer', 585), ('taste', 473), ('carbonation', 402), ('chocolate', 392), ('malt', 377), ('glass', 347), ('hops', 335), ('bit', 334), ('flavor', 332), ('finish', 311), ('lacing', 306), ('alcohol', 305), ('coffee', 298), ('body', 290), ('aroma', 289), ('color', 285), ('bitterness', 273), ('hop', 265), ('nose', 249)]\n",
      "review_appearance_adjs [('nice', 459), ('good', 414), ('dark', 405), ('sweet', 373), ('black', 311), ('thick', 292), ('great', 289), ('bitter', 271), ('smooth', 267), ('little', 256), ('roasted', 246), ('brown', 239), ('creamy', 235), ('more', 234), ('big', 221), ('full', 212), ('white', 194), ('light', 185), ('medium', 180), ('deep', 166)]\n",
      "review_palette_nouns [('head', 842), ('beer', 600), ('taste', 501), ('carbonation', 417), ('malt', 352), ('glass', 336), ('color', 336), ('lacing', 331), ('finish', 330), ('flavor', 326), ('bit', 320), ('chocolate', 313), ('hops', 305), ('aroma', 286), ('alcohol', 283), ('body', 266), ('nose', 265), ('flavors', 248), ('hop', 236), ('bottle', 233)]\n",
      "review_palette_adjs [('nice', 464), ('good', 425), ('sweet', 358), ('dark', 351), ('little', 285), ('more', 267), ('bitter', 262), ('great', 262), ('smooth', 246), ('black', 245), ('thick', 230), ('brown', 225), ('white', 223), ('full', 215), ('big', 209), ('light', 201), ('roasted', 189), ('creamy', 187), ('thin', 177), ('bodied', 171)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "source": [
    "def initialize_training_data(beers):\n",
    "    beers_training = []\n",
    "    for index, beer in beers.iterrows():\n",
    "        beer_review_label = {\n",
    "            \"cats\": {\n",
    "                \"aroma\": beer.review_aroma/5.0, # normalize ratings\n",
    "                \"taste\": beer.review_taste/5.0,\n",
    "                \"appearance\": beer.review_appearance/5.0,\n",
    "                \"palette\": beer.review_palette/5.0,\n",
    "                \"overall\": beer.review_overall/5.0\n",
    "            }\n",
    "        }\n",
    "        beers_training.append((beer.review_text, beer_review_label))\n",
    "    return beers_training\n",
    "\n",
    "beers_training = initialize_training_data(beers)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "source": [
    "# loosely based on https://realpython.com/sentiment-analysis-python/\n",
    "# but had to modify bc updated spacy package\n",
    "# and for multilabel cnn config\n",
    "\n",
    "def train_model(training_data, iterations:int = 10):\n",
    "    nlp = spacy.blank('en')\n",
    "    if \"textcat_multilabel\" not in nlp.pipe_names:\n",
    "        textcat = nlp.add_pipe(\"textcat_multilabel\", config=Config().from_str(multi_label_cnn_config))\n",
    "    else:\n",
    "        textcat = nlp.get_pipe(\"textcat_multilabel\")\n",
    "\n",
    "    textcat.add_label(\"aroma\")\n",
    "    textcat.add_label(\"taste\")\n",
    "    textcat.add_label(\"appearance\")\n",
    "    textcat.add_label(\"palette\")\n",
    "    textcat.add_label(\"overall\")\n",
    "\n",
    "    training_excluded_pipes = [pipe for pipe in nlp.pipe_names if pipe != \"textcat\"]\n",
    "\n",
    "    with nlp.disable_pipes(training_excluded_pipes):\n",
    "        optimizer = nlp.initialize()\n",
    "        # Training loop\n",
    "        print(\"Beginning training\")\n",
    "        batch_sizes = compounding(\n",
    "            4.0, 32.0, 1.001\n",
    "        )  # A generator that yields infinite series of input numbers\n",
    "        for i in range(iterations):\n",
    "            print(i)\n",
    "            loss = {}\n",
    "            random.shuffle(training_data)\n",
    "            batches = minibatch(training_data, size=batch_sizes)\n",
    "            for batch in batches:\n",
    "                examples = []\n",
    "                for text, label in batch:\n",
    "                    if isinstance(text, float):\n",
    "                        continue\n",
    "                    doc = nlp.make_doc(text)\n",
    "                    example = Example.from_dict(doc, label)\n",
    "                    examples.append(example)\n",
    "                nlp.update(\n",
    "                    examples,\n",
    "                    drop=0.2,\n",
    "                    sgd=optimizer,\n",
    "                    losses=loss\n",
    "                )\n",
    "    # Save model\n",
    "    with nlp.use_params(optimizer.averages):\n",
    "        nlp.to_disk(\"model_artifacts\")\n",
    "\n",
    "    pass\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "source": [
    "    # 4. If you were to recommend 3 beers to your friends based on this data which ones will you recommend?\n",
    "\n",
    "# I would use the similarity function to compare a description of the beer that I would consider ideal and compare that to all of the review_text columns\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "source": [
    "    # 5. Which Beer style seems to be the favorite based on reviews written by users? \n",
    "\n",
    "# search for \"favorite\" in the review text\n",
    "beer_styles = beers[beers['review_text'].str.contains('favorite', na=False)]\n",
    "# normalize by the # of beers in each style\n",
    "beer_style_favorites = (beer_styles.groupby('beer_style').size()/beers.groupby('beer_style').size()).nlargest(20)\n",
    "print(beer_style_favorites)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "beer_style\n",
      "Pumpkin Ale                  0.079809\n",
      "Gose                         0.077778\n",
      "MÃ¤rzen / Oktoberfest         0.071877\n",
      "Vienna Lager                 0.071165\n",
      "Tripel                       0.068660\n",
      "Oatmeal Stout                0.066934\n",
      "Schwarzbier                  0.066024\n",
      "Quadrupel (Quad)             0.065869\n",
      "Belgian Strong Dark Ale      0.065425\n",
      "Weizenbock                   0.064819\n",
      "Milk / Sweet Stout           0.062791\n",
      "Dortmunder / Export Lager    0.061913\n",
      "Witbier                      0.061618\n",
      "Rye Beer                     0.061595\n",
      "Maibock / Helles Bock        0.058388\n",
      "Lambic - Unblended           0.058156\n",
      "American Brown Ale           0.057620\n",
      "Czech Pilsener               0.057314\n",
      "American IPA                 0.057138\n",
      "Scotch Ale / Wee Heavy       0.057030\n",
      "dtype: float64\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "source": [
    "def compare_review(review:str):\n",
    "    nlp = spacy.load(\"model_artifacts\")\n",
    "    nlp.initialize()\n",
    "    text = nlp(review)\n",
    "    print(text)\n",
    "    print(text.cats)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "    # 6. How does written review compare to overall review score for the beer styles?\n",
    "\n",
    "# train model\n",
    "print(beers_training[0])\n",
    "train_model(beers_training)\n",
    "\n",
    "# evaluate the model (prob need to do better job splitting train/test data)\n",
    "# TODO: compare_review of the test data with the expected value\n",
    "# since the ratings are normalizes 0-1 and independent,\n",
    "# could test rmse for each of the five rating labels to see how text compares to ratings\n",
    "# group rmse results by style\n",
    "\n",
    "compare_review(\"I like a smooth finish on a beer.  The aroma was chocolatey goodness.  I didn't really care for the taste though.  The lacing in the glass was incredible, definitely my favorite beer.\")"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "('A lot of foam. But a lot. In the smell some banana, and then lactic and tart. Not a good start. Quite dark orange in color, with a lively carbonation (now visible, under the foam). Again tending to lactic sourness. Same for the taste. With some yeast and banana.', {'cats': {'aroma': 0.3, 'taste': 0.3, 'appearance': 0.5, 'palette': 0.4, 'overall': 0.3}})\n",
      "Beginning training\n",
      "0\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_24302/791095495.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# train model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeers_training\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbeers_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# evaluate the model (prob need to do better job splitting train/test data)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_24302/1873316413.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(training_data, iterations)\u001b[0m\n\u001b[1;32m     38\u001b[0m                     \u001b[0mexample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mExample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m                     \u001b[0mexamples\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m                 nlp.update(\n\u001b[0m\u001b[1;32m     41\u001b[0m                     \u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m                     \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, examples, _, drop, sgd, losses, component_cfg, exclude, annotates)\u001b[0m\n\u001b[1;32m   1106\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1107\u001b[0m         \u001b[0mvalidate_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Language.update\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1108\u001b[0;31m         \u001b[0mexamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_copy_examples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexamples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1109\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msgd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_optimizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m_copy_examples\u001b[0;34m(examples)\u001b[0m\n\u001b[1;32m   2081\u001b[0m     \u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \"\"\"\n\u001b[0;32m-> 2083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/language.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2081\u001b[0m     \u001b[0mLanguage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2082\u001b[0m     \"\"\"\n\u001b[0;32m-> 2083\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mExample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0meg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mexamples\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2084\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2085\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/tokens/doc.pyx\u001b[0m in \u001b[0;36mspacy.tokens.doc.Doc.copy\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/tokens/_dict_proxies.py\u001b[0m in \u001b[0;36mcopy\u001b[0;34m(self, doc)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdoc\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc_ref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mSpanGroups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/spacy/tokens/_dict_proxies.py\u001b[0m in \u001b[0;36mto_bytes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# know their names.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msrsly\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsgpack_dumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfrom_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbytes_data\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;34m\"SpanGroups\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/srsly/_msgpack_api.py\u001b[0m in \u001b[0;36mmsgpack_dumps\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mRETURNS\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mserialized\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \"\"\"\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmsgpack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_bin_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/srsly/msgpack/__init__.py\u001b[0m in \u001b[0;36mpackb\u001b[0;34m(o, **kwargs)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mPack\u001b[0m \u001b[0man\u001b[0m \u001b[0mobject\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mpacked\u001b[0m \u001b[0mbytes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \"\"\"\n\u001b[0;32m---> 55\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mPacker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/srsly/msgpack/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmsgpack_encoders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0mdefault\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchain\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdefault\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"default\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/challenge/lib/python3.9/site-packages/catalogue/__init__.py\u001b[0m in \u001b[0;36mget_all\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mREGISTRY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             if len(self.namespace) == len(keys) - 1 and all(\n\u001b[0;32m--> 111\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnamespace\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m             ):\n\u001b[1;32m    113\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "source": [
    "    # 7. How do find similar beer drinkers by using written reviews only?       \n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "beers_groups_by_drinker = beers.groupby(['review_profileName'], axis=0)\n",
    "\n",
    "# combine all of the reviews into one string\n",
    "# but limit the size of string bc performance\n",
    "size=100000\n",
    "a = nlp(beers_groups_by_drinker.get_group('RedDiamond')['review_text'].to_string()[0:size])\n",
    "b = nlp(beers_groups_by_drinker.get_group('jeff1973')['review_text'].to_string()[0:size])\n",
    "c = nlp(beers_groups_by_drinker.get_group('TheGordianKnot')['review_text'].to_string()[0:size])\n",
    "d = nlp(beers_groups_by_drinker.get_group('beerman207')['review_text'].to_string()[0:size])\n",
    "print('a, b',a.similarity(b))\n",
    "print('a, c',a.similarity(c))\n",
    "print('a, d',a.similarity(d))\n",
    "print('b, c',b.similarity(c))\n",
    "print('b, d',b.similarity(d))\n",
    "print('c, d',c.similarity(d))\n",
    "\n",
    "# RedDiamon and beerman207 seem to be the most similar linguistically\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "a, b 0.8673761341115795\n",
      "a, c 0.9623981847045289\n",
      "a, d 0.9791981038081332\n",
      "b, c 0.9251090939229425\n",
      "b, d 0.9005460133234128\n",
      "c, d 0.9695237770316095\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('challenge': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "interpreter": {
   "hash": "baa250f6f8c1c287502f4a0b8e2b54608768056c3e9579d8da337f5b83e836bc"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}